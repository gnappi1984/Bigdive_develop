{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"BIGDIVE_logo.png\" width=\"300\">\n",
    "<br>\n",
    "\n",
    "**designed for**\n",
    "\n",
    "<img src=\"Intesa.png\">\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "# NETWORK SCIENCE - practice\n",
    "\n",
    "### Claudio Borile\n",
    "\n",
    "<img src=\"aizoon.png\" width=\"150\" align=\"center\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "* [1. Introduction](#1.-Introduction)\n",
    "    * [1.1 Modules](#1.1-Modules)\n",
    "    * [1.2 Networkx primer](#1.2-Networkx-primer)\n",
    "        * [Nodes and edges](#Nodes-and-edges)\n",
    "        * [Adjacency matrix](#Adjacency-matrix)\n",
    "        * [I/O](#I/O)\n",
    "        * [Visualization](#Visualization)\n",
    "* [2. Airports network](#2.-Airports-network)\n",
    "    * [2.1. Network construction](#2.1.-Network-construction)\n",
    "    * [2.2. Connected components](#2.2.-Connected-components)\n",
    "    * [2.3. Network description](#2.3.-Network-description)\n",
    "    * [2.4. Network robustness](#2.4.-Network-robustness)\n",
    "    * [2.5. Paths](#2.5.-Paths)\n",
    "    * [2.6. Anomaly](#2.6.-Anomaly)\n",
    "* [3. A simple reccomender system](#3.-A-simple-reccomender-system)\n",
    "    * [3.1. Movielens dataset](#3.1.-Movielens-dataset)\n",
    "* [4. Community detection](#4.-Community-detection)\n",
    "    * [Girvan - Newman algorithm](#Girvan-Newman-algorithm)\n",
    "    * [Modularity](#Modularity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n",
    "You have learned about the basic theory behind network analysis and graph theory in the previous class, now it's time for a hands-on on those concepts to see how they can be applied in your daily practice using Python.\n",
    "\n",
    "## 1.1 Modules\n",
    "\n",
    "In this notebook we will use:\n",
    "- networkx\n",
    "- pandas/numpy/scipy\n",
    "- matplotlib\n",
    "- **optional**: seaborn, plotly\n",
    "\n",
    "first of all, import the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%pylab inline\n",
    "#import numpy as np\n",
    "\n",
    "import seaborn as sb\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Networkx primer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Networkx** is a Python package that allows to easily create and manipulate graphs, it contains pretty much all the standard graph models, methods and algorithms that we will use today (and much more!).\n",
    "\n",
    "The complete documentation can be found <a href=\"https://networkx.github.io/documentation/stable/index.html\"> here</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, the main object is obviously the **graph**. NX supports undirected, directed, multi, etc. graph types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nodes and edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now G is an empty container. The structure of the graph will be determined once we add **nodes** and **edges** to our graph G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_node(1)\n",
    "G.add_node('a') #the type of the node can be whatever...\n",
    "\n",
    "G.add_edge('a', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nodes and edges can be endowed with **attributes**,\n",
    "\n",
    "(**N.B.** if I create an edge referring to non-existing nodes, they are automatically created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_edge(2, 3, weight=5)\n",
    "G.add_node('isolated', p = \"it is isolated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can get all nodes or edges with or without attributes in various ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Only nodes\\n', G.nodes())\n",
    "print('Nodes with all attributes (dict type)\\n', G.nodes(data=True))\n",
    "print('Single attribute (tuple type)\\n', G.nodes(data='p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Only edges\\n', G.edges())\n",
    "print('Edges with all attributes (dict type)\\n', G.edges(data=True))\n",
    "print('Single attribute (tuple type)\\n', G.edges(data='weight'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "edges and nodes can be added in bunches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_list = [(10, 11), (12, 13), (14, 15), (16, 17, {'weight': 124})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_edges_from(edges_list)\n",
    "G.edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjacency matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adjacency matrix $A$ of a graph $G=(V, E)$ is defined as the $N\\times N$ matrix (where N is the number of nodes of G) whose entries are given by\n",
    "\n",
    "$A_{ij} = w_{ij}>0$ if $(i, j)\\in E$\n",
    "\n",
    "$A_{ij} = 0$ otherwise\n",
    "\n",
    "if the graph is **unweighted** $w_{ij} \\in \\{0, 1\\}$, if the graph is **undirected** $A_{ij} = A_{ji}\\ \\forall i, j \\in V$\n",
    "\n",
    "it is a way of encoding the graph structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(10, 7)\n",
    "ax = sb.heatmap(nx.to_pandas_adjacency(G, weight=None), linewidths=.9, cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, usually we don't want to create a network by inserting manually all nodes and edges, and a way to read and/or write networks to file is in order\n",
    "\n",
    "NX offers many different formats, the most common and basic being the edgelist and the adjacency matrix formats\n",
    "\n",
    "Other formats (.gml, .gexf, ...) might be useful for later use in web application of visualization softwares (see later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.erdos_renyi_graph(100, 0.1, directed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_edgelist(G, './ER_graph.edgelist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_edgelist('./ER_graph.edgelist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 0:** Here we can se a common problem when naively importing a file, can you see what the problem is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:** NX provides a series of built-in methods for generating graphs (<a href=\"https://networkx.github.io/documentation/networkx-1.10/reference/generators.html\">here</a> the documentation). Generate, for N=1000 number of nodes, a random regular graph, Erdos-Renyi, watts-strogatz and a scale free graph.\n",
    "\n",
    "Describe the obtained graphs through classic graphs' metrics, what are the main differences? (tune the parameters of the generators in order to have comparable graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NX provides a set of methods for drawing a network, where almost all components of the network can be personalized. One of the most important component when visualizing a network is the layout algorithm.\n",
    "\n",
    "<a href=\"https://en.wikipedia.org/wiki/Graph_drawing\">Link to the wikipedia page about graph drawing</a>\n",
    "\n",
    "**N.B.** That of _graph drawing_ is almost an art (<a href=\"http://www.theartofnetworks.com/\">really!</a>), so it is difficult to effectively visualize a network, especially when large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most layout algorithms are dynamical systems where the \"particles\" (nodes) are attracted end repelled through electromagnetic and gravitational forces, and the intensity of these forces is given by attributes like degree and edges' weights. Because of this the convergence (if existing) of these algorithms might be very slow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G =nx.barabasi_albert_graph(50, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {n: np.random.randint(100) for n in G.edges()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_edge_attributes(G, weights, 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "degrees_dict = G.degree()\n",
    "strength_dict = G.degree(weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = pd.Series(dict(G.degree()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_list = G.nodes()\n",
    "e_list = [(i, j) for i, j in G.edges()]\n",
    "w_list = [w['weight']/10. for i, j, w in G.edges(data=True)]\n",
    "s_list = [degrees_dict[s]*1000. for s in n_list]\n",
    "#s_list = [strength_dict[s]/500. for s in n_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 40))\n",
    "\n",
    "#compute the nodes' position based on weights\n",
    "pos = nx.spring_layout(G, k=10., iterations=5000, weight='weight')\n",
    "\n",
    "#draw network edges\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.1, edgelist=e_list, width=w_list)\n",
    "\n",
    "#draw network nodes\n",
    "nx.draw_networkx_nodes(G, pos = pos, alpha=0.2, node_size=s_list, nodes_color = 'orange', nodelist=n_list)\n",
    "\n",
    "# Print node labels separately\n",
    "for n in n_list:\n",
    "    plt.annotate(n,\n",
    "        xy = pos[n],\n",
    "        textcoords = 'offset points',\n",
    "        horizontalalignment = 'center',\n",
    "        verticalalignment = 'center',\n",
    "        xytext = [0, 0],\n",
    "        #fontsize = k[n],\n",
    "        fontsize = 1.*strength_dict[n]/10.,         \n",
    "        color = 'darkorange'\n",
    "    )\n",
    "plt.axis('off')\n",
    "#plt.savefig(\"network.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a href=\"https://gephi.org/\">Gephi</a> demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**N.B.** Unlike machine learning and pattern recognition, where the goal is clearly defined, network analysis provides only a mathematical framework -a modelization of the problem, in the form of individual entities and relations between them- and a set of tools, but you have to figure out what kind of information you want to extract from the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Airports network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file **routes.dat** contains information about the global flights' network. Each row represents an airline flight, with source and destination. The network structure of this data is evident. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Network construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:** load the file routes.dat in a pandas dataframe, do some preliminary analysis on the data structure and build the corresponding (directed, weighted) graph where \n",
    "- the nodes are given by the airports\n",
    "- a link is drawn from A to B if there is one or more airline doing the route A->B\n",
    "- the weight of the link is given by the total number of flights from A to B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Connected components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this specific network connected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = sorted([len(c) for c in nx.strongly_connected_components(G_flights)], reverse=True)\n",
    "print ('Connected components:', components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph is not connected, and it is clearly showing a giant connected component (extensive in the size $N$ of the graph) and many components made of few nodes. This is typical of many real-world networks.\n",
    "\n",
    "The second largest components is the network of internal flights in new caledonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([c for c in nx.strongly_connected_components(G_flights)], reverse=True, key=len)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on let's take only the largest connected components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:** Redefine G_flights as the network given by keeping only the largest connected component of the original network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Network description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4:** What are the basic metrics (centralities, main distributions, ...) of this network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5:** Build and visualize the graph's giant component adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4. Network robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **giant component** is a connected component of a given random graph that contains a constant fraction of the entire graph's vertices.\n",
    "\n",
    "For random removal of nodes, the giant component of a binomial random graphs breaks at the critical point $f_c = 1 - \\frac{1}{\\langle k \\rangle}$ (see Barabasi). Scale-free networks, due to the presence of hubs, are more robust.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that a computer virus is crashing the communication system of one random airport at the time, what is the expected number of nodes that have fail so that the network breaks apart?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = G_flights.copy()\n",
    "l = []\n",
    "i = 0\n",
    "nodes_list = list(g.nodes())\n",
    "while len(nodes_list) > 0:\n",
    "    if i%10 == 0:\n",
    "        print (i, end=' ')\n",
    "        cc = len(sorted([c for c in nx.strongly_connected_components(g)], reverse=True, key=len)[0])\n",
    "        p = 1.*cc/len(G_flights.nodes())\n",
    "        l.append((i, p))\n",
    "    i+=1\n",
    "    rnd_node = nodes_list[random.randint(len(nodes_list))]\n",
    "    g.remove_node(rnd_node)\n",
    "    nodes_list = list(g.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail = pd.Series(l).apply(pd.Series).set_index(0)\n",
    "fail.columns = ['random failure']\n",
    "fail.plot(figsize=(15, 10), grid=True, style='o-');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6**: Now the virus is getting smarter, and instead of attacking a random node it gets first the hubs. How many nodes does he have to attack now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7:** What would happen in a purely random network (Erdos-Renyi)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8:** Show all the shortest paths for getting from Turin (TRN) to Linz (LNZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 9:** Find and plot all airports that can be reached with a distance of max 2 hops from Turin and Milan. How are they different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you know, the **betweennes** centrality of a node measures how much that node act as a bridge connecting all the other nodes, in terms of shortest paths. \n",
    "\n",
    "$\\displaystyle\\mathcal{B} = \\sum_{s\\neq v\\neq t}\\frac{\\sigma(s, t | v)}{\\sigma(st)}$\n",
    "\n",
    "Networkx provides a built-in version of the algorithm for computing the beweenness (like very much _all_ standard algorithms on graphs).\n",
    "\n",
    "If we compute the betweenness for the flights network, we can see that something's unexpected! \n",
    "\n",
    "**Exercise 10:** Compute the betweenness centrality for all airports and answer:\n",
    "- which airport is the most central?\n",
    "- What's _quantitatively_ strange? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. A simple reccomender system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the case where you have data about a group of users and a series of items they bought/interacted with (a store, media consumption, etc.). We would like to be able to reccomend new products to users based on what similar users liked.\n",
    "\n",
    "We can intuitively associate a bipartite network* user->item to our system and exploit this data structure to build the simplest reccomender engine.\n",
    "\n",
    "*a **bipartite network** is a network $G=(V, E)$ where $V = A\\cup B,\\ A\\cap B = \\emptyset$ and $(i, j) \\in E \\Rightarrow\\ i\\in U, j\\in V\\setminus U,\\ U=A, B$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest approach to a reccomender system is that of **collaborative filtering**.\n",
    "\n",
    "<center><img src=\"cf.png\" width=\"500\"></center>\n",
    "    \n",
    "    image taken from https://d4datascience.wordpress.com/2016/07/22/recommender-systems-101/ \n",
    "\n",
    "\n",
    "The idea is to associate a similarity score to each of the users or items and reccomend a specific user items based on what the most similar users bought.\n",
    "\n",
    "For a (undirected) bipartite graph the adjacency matrix is in the form \n",
    "\n",
    "$A = \\begin{bmatrix}\n",
    "0 & B \\\\\n",
    "B^{T} & 0 \n",
    "\\end{bmatrix}$\n",
    "\n",
    "where $B$ is a $N\\times M$ matrix, with $N$ number of nodes in $A$ (users) and $M$ number of nodes in $B$ (items). We can work on the matrix $B$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.matrix([[1, 1, 0, 0], [1, 1, 1, 0], [0, 0, 1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = np.linalg.norm(B, axis=1)\n",
    "S = B.dot(B.T)/np.outer(norm, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1 = S-np.identity(S.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B[argmax(S1[0, :])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1. Movielens dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider now a dataset of movie ratings from online users. We have two files in the ml-latest-small directory:\n",
    "- ratings.csv\n",
    "- movies.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 11:** Describe the dataset, preprocess it in order to have a single dataframe containing the following informations: userId, movieId, rating, title. Try to apply the same process seen above in order to build a reccomender system for an online movie service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this similarity matrix to try to predict the missing ratings (ratings to movies that users have not seen) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = S.dot(B)/np.matrix(np.linalg.norm(S, ord=1, axis=1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reccomandation_df = pd.DataFrame(R, index=user_item_df.index, columns=columns_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reccomandation_df.iloc[:5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_mse(pred, actual):\n",
    "    # Ignore nonzero terms.\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_squared_error(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mse(R, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a baseline error for the simplest, model independent, reccomender system. More refined engines must score better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Community detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Community detection is an _ill defined_ problem. We are trying to assign to each node a label without knowing the ground truth (yes, it's a clustering). Furthermore usually we don't know how many communities we are looking for.\n",
    "That is why there are so many different CD algorithms, with a great variety of mathematical and logical approaches to tackle the problem, and why it's so crucial to assess the best option for the specific case under scrutiny.\n",
    "\n",
    "We must be careful when running community detection algorithms!\n",
    "\n",
    "General reference: <a href=\"http://networksciencebook.com/chapter/9\"> Barabasi - Network science - chapter 9 </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Girvan Newman algorithm\n",
    "\n",
    "Original article: http://www.pnas.org/content/99/12/7821.full.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 12:** Implement the Girvan-Newman algorithm for the flights operated by Alitalia (airline = AZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 13:** What kind of result was returned by the algorithm? What does it mean? What would you do to extract information from it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little bit more structured:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **modularity** of a network is a measure of _structure_. Given a grouping of the vertices of a graph, the modularity is defined as the number of edges within the group over the expected number of edges if they were assigned at random. The modularity can thus be used to assess the goodness of the found communities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 14:** Write a python function for computing the modularity of a network partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 15:** Assign to each node in G_AZ its community as a property of the graph and save the graph as an edgelist with the community property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
